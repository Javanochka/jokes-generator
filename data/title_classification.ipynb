{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "title_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjDBkuOpXU3l",
        "colab_type": "code",
        "outputId": "9ac78ad9-c0f6-44a0-8bd0-d0f989df3628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX4mB58LbgbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "posts = []\n",
        "\n",
        "with open('/content/drive/My Drive/DL project/data_jokes_clean.json', 'r') as fin:\n",
        "  posts = json.load(fin)['posts']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKn_CH_IcLai",
        "colab_type": "code",
        "outputId": "7250734c-941a-47e5-a713-97195f9a8a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(posts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106355"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg2yA603cQBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = []\n",
        "\n",
        "for post in posts:\n",
        "    if len((post['title'] + \" \" + post['text']).split()) > 100:\n",
        "        continue\n",
        "    corpus.append(post['title'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU5ms2dVdE8g",
        "colab_type": "code",
        "outputId": "7cd059bd-883e-4e95-8940-02ad7bc8c72e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "corpus[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I hope you're all getting your Walter Cronkite jokes in order. He's next. \",\n",
              " 'What is the only thing a woman can say that will make a man feel both happy and sad at the same time?\\n',\n",
              " 'Why is gambling not allowed in Africa?',\n",
              " 'Husband Asks Wife \"What would you do if I hit the lottery?\"',\n",
              " \"(Warning, this is worse than those laffy-taffy jokes) Why don't engineers have sex with much frequency?\",\n",
              " 'Beware of alphabet grenades...',\n",
              " \"What's big, gray and unimportant?\",\n",
              " 'New Daily Joke WTF??',\n",
              " '2 Scottish cows in a field: which one is on holiday?',\n",
              " 'A priest and a rabi are on a walk together when the pass a schoolyard with children playing in it. ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrb6nrDKdGT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwvmhBE0dTy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X = vectorizer.fit_transform(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISmzlqv0dY5v",
        "colab_type": "code",
        "outputId": "39f7cb51-a59e-4d4c-f400-88ec8ccb3215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86178, 24035)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9ObfMD2daPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "clust = KMeans(n_clusters=10)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgijXGKfeo_y",
        "colab_type": "code",
        "outputId": "f4a908aa-5163-448e-f5f2-9072689f4ab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "clust.fit(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=10, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=None, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NuoJpINew-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = clust.labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVQ29EiThmdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic = {}\n",
        "\n",
        "for title, cluster in zip(corpus, result):\n",
        "    if cluster not in dic:\n",
        "        dic[cluster] = []\n",
        "    dic[cluster].append(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBsAOBP5h5Z7",
        "colab_type": "code",
        "outputId": "49bcca8f-454d-4dca-a3bf-c8024acf6b77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dic.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([0, 3, 2, 1, 9, 6, 8, 7, 5, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpvivP3jh_EK",
        "colab_type": "code",
        "outputId": "4089c744-8012-449c-8b7c-3e40c5058477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "dic[0][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I hope you're all getting your Walter Cronkite jokes in order. He's next. \",\n",
              " 'Beware of alphabet grenades...',\n",
              " \"What's big, gray and unimportant?\",\n",
              " 'A priest and a rabi are on a walk together when the pass a schoolyard with children playing in it. ',\n",
              " 'When god gives you AIDS...',\n",
              " 'The 3 tragedies.',\n",
              " 'Why did Mary Poppins break both her legs?',\n",
              " 'Iceland passed away last week...',\n",
              " 'What does a gay horse eat? ',\n",
              " 'Your mama so hairy...']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJpLLCFliVsC",
        "colab_type": "code",
        "outputId": "0451f968-e74e-4c2e-916e-118bd517a5b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "dic[1][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['New Daily Joke WTF??',\n",
              " 'What do a short-sighted gynaecologist and a puppy have in common?',\n",
              " 'Running in the Marathon (funny Joke)',\n",
              " 'Old joke perfect for redditors.',\n",
              " 'Irish joke ',\n",
              " 'What do a pizza delivery man and a gynecologist have in common?',\n",
              " 'Can someone repost that joke from the other day about the lady scrambling an egg?',\n",
              " 'These Black and Mexican jokes have gone too far',\n",
              " 'What does a walrus and Tupperware have in common?',\n",
              " 'Have you heard my under construction joke?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jAQfw_xiXWR",
        "colab_type": "code",
        "outputId": "d5934e28-d94a-44ae-b84e-1ecbdf45eb5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "dic[2][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Husband Asks Wife \"What would you do if I hit the lottery?\"',\n",
              " 'What do you get when you combine a Comedian and a Whorehouse?',\n",
              " 'What do you call someone who really hates burnt bread?',\n",
              " 'How do you catch a unique rabbit?',\n",
              " 'How do you titillate an ocelot?',\n",
              " 'What do you call a guy who likes to hang out with musicians?\\n',\n",
              " 'In a Catholic boarding school, how do you know when to go to bed?',\n",
              " 'Where do you find a turtle with no legs?',\n",
              " 'What do Americans do immediately after winning the World Cup (Soccer)?',\n",
              " 'My 5 year old told me this joke:  What do you call a puppy in the desert?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "590PyIgVidJh",
        "colab_type": "code",
        "outputId": "62a4277e-bc43-4238-f645-e382e74149e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "dic[3][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What is the only thing a woman can say that will make a man feel both happy and sad at the same time?\\n',\n",
              " 'Why is gambling not allowed in Africa?',\n",
              " \"(Warning, this is worse than those laffy-taffy jokes) Why don't engineers have sex with much frequency?\",\n",
              " '2 Scottish cows in a field: which one is on holiday?',\n",
              " 'What is hard and six inches long?',\n",
              " 'What is the hardest part of a vegetable to eat?',\n",
              " 'So this lady is checking out at the grocery store...',\n",
              " 'Piracy is killing the music industry.\\n',\n",
              " 'Who is the biggest prostitute alive?',\n",
              " \"If the opposite of pro is con, what's the opposite of \\r\\nprogress?\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2QiLrrUifrt",
        "colab_type": "code",
        "outputId": "7a6edaf6-64dd-4a84-d847-1029c3b2a44b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "dic[4][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My wife is a famous porn star.',\n",
              " 'My wife was gang raped by a troupe of mimes....\\n',\n",
              " 'What would you get if your donkey ate the legs off my rooster?',\n",
              " 'My mate in Scotland reckons his scrotum got to -273 degrees last night.',\n",
              " 'My old man got admitted to a psychiatric hospital today. He had set up a traffic detour through his house.',\n",
              " 'My father told me that I was an accident...',\n",
              " 'Man A: Would you suck my cock if I cleaned it?',\n",
              " 'I bought a metronome recently, I left it in my car as I stopped at the bank machine for a minute, came back and it was gone, someone stole it but was caught...',\n",
              " 'I was shocked when a five year old told me this joke yesterday',\n",
              " 'I just quite my job at the helium factory.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmK0Cn93ijRH",
        "colab_type": "code",
        "outputId": "0d8ef419-d66d-4711-c464-5b2c5924dbea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "dic[5][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['So a guy walks into a whorehouse and says...',\n",
              " 'A man walks into a bar and orders 12 shots of tequila. . .',\n",
              " '\\nA man walks into a bar with a giraffe',\n",
              " 'A Social Media Consultant walks into a bar and orders a drink.',\n",
              " '\"A SQL query walks into a bar.',\n",
              " 'Seal walks into a.....',\n",
              " 'A skeleton goes into a bar...',\n",
              " 'A farmer walks into his bedroom with a duck under his arm',\n",
              " 'A Priest a Rabbi and a Nun walk into a bar',\n",
              " 'A piece of string walks into a bar']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsL2e_zWilMf",
        "colab_type": "code",
        "outputId": "9bbaee5e-8652-4f34-a273-c836431f94d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "dic[6][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Did you hear about the constipated mathematician? ',\n",
              " 'Did you hear about the constipated accountant?',\n",
              " 'What did the cheese maker say after his factory was hit by lightning?',\n",
              " 'What did the egg say to the boiling water? ',\n",
              " 'What did the cannibal do after he dumped his girlfriend?',\n",
              " 'Why did Gateway computers go out of business?',\n",
              " 'Did you hear about the logical skunk?',\n",
              " 'What did the Zombie Plumber cry?',\n",
              " 'Did you hear about the man who had sex with a parrot?',\n",
              " 'Did you hear about the guy who lost his left arm and left leg in a car accident? ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpkjcX4ciqex",
        "colab_type": "code",
        "outputId": "2f027077-48c4-4187-f047-37fba817ed60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "dic[7][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['knitting - Not all mothers like this.',\n",
              " 'Why do rednecks like Halloween?',\n",
              " 'Relationships are like fat people...',\n",
              " 'Finish this sentence: I like my coffee like I like my _____.',\n",
              " \"How is being married like puttin' on a tin roof?\",\n",
              " 'Marriage is like a deck of cards... ',\n",
              " 'I like my (wo)men like I like my coffee: _________ (fill in the blank)',\n",
              " 'Spinach is alot like buttsex...',\n",
              " 'What do troll mathematicians like to solve?',\n",
              " \"My girlfriend's body is like poetry...\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COreZ04Dixzd",
        "colab_type": "code",
        "outputId": "2f11b91d-f429-4408-e5b7-b8791cbd1f6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "dic[8][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What is the difference between love and lust?',\n",
              " 'What is the difference between Tiger Woods and Princess Di....',\n",
              " \"What's the difference between a Jew and a canoe?\",\n",
              " \"What's the difference between a musician and a large cheese pizza?\\n\",\n",
              " \"What's the difference between oral sex and anal sex?\",\n",
              " \"What's the difference between a mistress and a wife?\",\n",
              " 'Whats the difference between jam and jelly?',\n",
              " \"What's the difference between an oral thermometer and a rectal thermometer?\",\n",
              " 'What is the difference between a crack dealer and a prostitute?',\n",
              " 'Whats the difference between Peanut butter and Jam?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PlN_uJMlz0i",
        "colab_type": "code",
        "outputId": "491f418d-47d5-480b-8453-59eed816f99a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "dic[9][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Here's a joke just for reddit: How many narwhals does it take to screw in a light bulb?\",\n",
              " 'Q: How many surrealists does it take to change a lightbulb?',\n",
              " 'How Many Hipsters Does it Take to Screw in a Lightbulb?',\n",
              " 'How many pregnant women does it take to screw in a lightbulb?',\n",
              " 'How many feminists does it take to screw in a lightbulb?',\n",
              " 'How many hipsters does it take to change a light bulb?',\n",
              " 'How many Irish folk singers does it take to change a light bulb?',\n",
              " 'How many hipsters does it take to screw in a lighbulb?',\n",
              " 'How many Norwegians does it take to change a light bulb?',\n",
              " 'How many punks does it take to change a light bulb?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2VRoX9Xl1X8",
        "colab_type": "code",
        "outputId": "8f1a527f-0b23-4be7-a88d-18baebac0a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "for i in range(10):\n",
        "    print(i, len(dic[i]))\n",
        "    print(max([len(t.split()) for t in dic[i]]))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 42370\n",
            "58\n",
            "1 5342\n",
            "47\n",
            "2 8589\n",
            "54\n",
            "3 5832\n",
            "53\n",
            "4 6995\n",
            "56\n",
            "5 2440\n",
            "33\n",
            "6 7643\n",
            "53\n",
            "7 2493\n",
            "43\n",
            "8 3072\n",
            "25\n",
            "9 1402\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc_ZhtLz08Vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq4DvVCl7v88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = []\n",
        "\n",
        "word_for_num = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
        "\n",
        "for i in range(10):\n",
        "    for title in dic[i]:\n",
        "        to_add = process_to_tokens(f\" title{word_for_num[i]} titlestart \" + title + \" titleend \")\n",
        "        if (len(to_add) < 40):\n",
        "            texts.append(to_add)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fe1Oi2w8jgt",
        "colab_type": "code",
        "outputId": "964fbef3-3f3f-4e03-f9b4-9d22f5b5612f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85980"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8nM_9-UpS6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LI7Amk38lD5",
        "colab_type": "code",
        "outputId": "204e92ce-b98c-489b-b3d5-971a4ad901a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "bptt = 50\n",
        "lang_model = spacy.load('en', disable=['tagger', 'parser', 'ner'])\n",
        "\n",
        "\n",
        "def process_to_tokens(text):\n",
        "    sentence = [tok.text for tok in lang_model.tokenizer(text) if not tok.text.isspace()]\n",
        "    sentence = [\"<sos>\"] + sentence\n",
        "    if len(sentence) > bptt or len(sentence) < 7:\n",
        "      return []\n",
        "    sentence += ['<pad>'] * max(0, bptt - len(sentence))\n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGlWkV2bsehr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = []\n",
        "\n",
        "for post in posts:\n",
        "  sent = process_to_tokens(post['title'] + \" textdelimeter \" + post['text'])\n",
        "  if len(sent) > 0:\n",
        "    texts.append(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g6fAAsqtFjv",
        "colab_type": "code",
        "outputId": "83705386-2e10-45ee-8d9a-d7efa352a820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72444"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbk0iDSWAtcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_from_texts(texts, batch_size, seq_size):\n",
        "    stext = []\n",
        "    for text in texts:\n",
        "        stext += text\n",
        "    word_counts = Counter(stext)\n",
        "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "    int_to_vocab = {k: w for k, w in enumerate(sorted_vocab)}\n",
        "    vocab_to_int = {w: k for k, w in int_to_vocab.items()}\n",
        "    n_vocab = len(int_to_vocab)\n",
        "\n",
        "    print('Vocabulary size', n_vocab)\n",
        "\n",
        "    int_texts = [[vocab_to_int[w] for w in text] for text in texts]\n",
        "    num_batches = int(len(int_texts) / (batch_size))\n",
        "    in_text = np.zeros((num_batches, batch_size, seq_size), dtype=np.int64)\n",
        "    for i in range(num_batches):\n",
        "        for j in range(batch_size):\n",
        "            in_text[i][j] = int_texts[i * batch_size + j]\n",
        "    out_text = np.zeros_like(in_text, dtype=np.int64)\n",
        "    for i in range(num_batches):\n",
        "        for j in range(batch_size):\n",
        "            out_text[i][j] = int_texts[i * batch_size + j][1:] + [vocab_to_int['<pad>']]\n",
        "    return int_to_vocab, vocab_to_int, n_vocab, in_text, out_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlMzhUoAAzst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import os\n",
        "from argparse import Namespace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPlE30NVA2vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(in_text, out_text, batch_size, seq_size):\n",
        "    num_batches = in_text.shape[0]\n",
        "    for i in range(0, num_batches):\n",
        "        yield in_text[i], out_text[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIBY-kziA9xX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNModule(nn.Module):\n",
        "    def __init__(self, n_vocab, seq_size, embedding_size, lstm_size):\n",
        "        super(RNNModule, self).__init__()\n",
        "        self.seq_size = seq_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
        "        self.lstm = nn.LSTM(embedding_size,\n",
        "                            lstm_size,\n",
        "                            batch_first=True)\n",
        "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.dense(output)\n",
        "\n",
        "        return logits, state\n",
        "    def zero_state(self, batch_size):\n",
        "        return (torch.zeros(1, batch_size, self.lstm_size),\n",
        "                torch.zeros(1, batch_size, self.lstm_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66WJxmK-BAhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_loss_and_train_op(net, lr=0.001):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "    return criterion, optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBm37dP6BK7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flags = Namespace(\n",
        "    seq_size=50,\n",
        "    batch_size=64,\n",
        "    embedding_size=64,\n",
        "    lstm_size=64,\n",
        "    gradients_norm=5,\n",
        "    predict_top_k=5,\n",
        "    checkpoint_path='checkpoint',\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GYVzWThBFqn",
        "colab_type": "code",
        "outputId": "ac6e5260-514a-47ea-9914-df287843c081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "int_to_vocab, vocab_to_int, n_vocab, in_text, out_text = get_data_from_texts(\n",
        "    texts, flags.batch_size, flags.seq_size)\n",
        "print(device)\n",
        "net = RNNModule(n_vocab, flags.seq_size,\n",
        "                flags.embedding_size, flags.lstm_size)\n",
        "net = net.to(device)\n",
        "\n",
        "criterion, optimizer = get_loss_and_train_op(net, 0.01)\n",
        "\n",
        "iteration = 0\n",
        "\n",
        "for e in range(50):\n",
        "    batches = get_batches(in_text, out_text, flags.batch_size, flags.seq_size)\n",
        "    state_h, state_c = net.zero_state(flags.batch_size)\n",
        "        \n",
        "    # Transfer data to GPU\n",
        "    state_h = state_h.to(device)\n",
        "    state_c = state_c.to(device)\n",
        "    for x, y in batches:\n",
        "        iteration += 1\n",
        "        net.train()\n",
        "        optimizer.zero_grad()\n",
        "        x = torch.tensor(x).to(device)\n",
        "        y = torch.tensor(y).to(device)\n",
        "\n",
        "        logits, (state_h, state_c) = net(x, (state_h, state_c))\n",
        "        loss = criterion(logits.transpose(1, 2), y)\n",
        "\n",
        "        state_h = state_h.detach()\n",
        "        state_c = state_c.detach()\n",
        "\n",
        "        loss_value = loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        _ = torch.nn.utils.clip_grad_norm_(\n",
        "            net.parameters(), flags.gradients_norm)\n",
        "\n",
        "        optimizer.step()\n",
        "        if iteration % 100 == 0:\n",
        "            print('Epoch: {}/{}'.format(e, 200),\n",
        "                  'Iteration: {}'.format(iteration),\n",
        "                  'Loss: {}'.format(loss_value))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size 48249\n",
            "cuda\n",
            "Epoch: 0/200 Iteration: 100 Loss: 2.541651725769043\n",
            "Epoch: 0/200 Iteration: 200 Loss: 2.8147497177124023\n",
            "Epoch: 0/200 Iteration: 300 Loss: 2.3719708919525146\n",
            "Epoch: 0/200 Iteration: 400 Loss: 2.393275260925293\n",
            "Epoch: 0/200 Iteration: 500 Loss: 2.068713665008545\n",
            "Epoch: 0/200 Iteration: 600 Loss: 2.386644124984741\n",
            "Epoch: 0/200 Iteration: 700 Loss: 2.2743136882781982\n",
            "Epoch: 0/200 Iteration: 800 Loss: 2.2600276470184326\n",
            "Epoch: 0/200 Iteration: 900 Loss: 2.1037588119506836\n",
            "Epoch: 0/200 Iteration: 1000 Loss: 2.2518248558044434\n",
            "Epoch: 0/200 Iteration: 1100 Loss: 2.163620948791504\n",
            "Epoch: 1/200 Iteration: 1200 Loss: 2.308948516845703\n",
            "Epoch: 1/200 Iteration: 1300 Loss: 1.8768832683563232\n",
            "Epoch: 1/200 Iteration: 1400 Loss: 1.94279146194458\n",
            "Epoch: 1/200 Iteration: 1500 Loss: 2.1292624473571777\n",
            "Epoch: 1/200 Iteration: 1600 Loss: 2.201812267303467\n",
            "Epoch: 1/200 Iteration: 1700 Loss: 1.9532058238983154\n",
            "Epoch: 1/200 Iteration: 1800 Loss: 1.7803313732147217\n",
            "Epoch: 1/200 Iteration: 1900 Loss: 2.0572402477264404\n",
            "Epoch: 1/200 Iteration: 2000 Loss: 2.014120578765869\n",
            "Epoch: 1/200 Iteration: 2100 Loss: 1.9712711572647095\n",
            "Epoch: 1/200 Iteration: 2200 Loss: 2.283106803894043\n",
            "Epoch: 2/200 Iteration: 2300 Loss: 1.9016014337539673\n",
            "Epoch: 2/200 Iteration: 2400 Loss: 1.7491161823272705\n",
            "Epoch: 2/200 Iteration: 2500 Loss: 1.6593337059020996\n",
            "Epoch: 2/200 Iteration: 2600 Loss: 1.5864394903182983\n",
            "Epoch: 2/200 Iteration: 2700 Loss: 1.9497038125991821\n",
            "Epoch: 2/200 Iteration: 2800 Loss: 1.705754280090332\n",
            "Epoch: 2/200 Iteration: 2900 Loss: 1.8084378242492676\n",
            "Epoch: 2/200 Iteration: 3000 Loss: 1.7757443189620972\n",
            "Epoch: 2/200 Iteration: 3100 Loss: 1.6949658393859863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLQpqM16UlQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iteration = 0\n",
        "\n",
        "for e in range(50):\n",
        "    batches = get_batches(in_text, out_text, flags.batch_size, flags.seq_size)\n",
        "    state_h, state_c = net.zero_state(flags.batch_size)\n",
        "        \n",
        "    # Transfer data to GPU\n",
        "    state_h = state_h.to(device)\n",
        "    state_c = state_c.to(device)\n",
        "    for x, y in batches:\n",
        "        iteration += 1\n",
        "        net.train()\n",
        "        optimizer.zero_grad()\n",
        "        x = torch.tensor(x).to(device)\n",
        "        y = torch.tensor(y).to(device)\n",
        "\n",
        "        logits, (state_h, state_c) = net(x, (state_h, state_c))\n",
        "        loss = criterion(logits.transpose(1, 2), y)\n",
        "\n",
        "        state_h = state_h.detach()\n",
        "        state_c = state_c.detach()\n",
        "\n",
        "        loss_value = loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        _ = torch.nn.utils.clip_grad_norm_(\n",
        "            net.parameters(), flags.gradients_norm)\n",
        "\n",
        "        optimizer.step()\n",
        "        if iteration % 100 == 0:\n",
        "            print('Epoch: {}/{}'.format(e, 200),\n",
        "                  'Iteration: {}'.format(iteration),\n",
        "                  'Loss: {}'.format(loss_value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91e3OHwVBOzh",
        "colab_type": "code",
        "outputId": "60470491-7e9e-4925-9ec0-1d224bf60d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "torch.save(net, \"/content/drive/My Drive/DL project/jokes_model_1.pth\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RNNModule. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8xvY4B31QSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(device, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
        "    net.eval()\n",
        "\n",
        "    state_h, state_c = net.zero_state(1)\n",
        "    state_h = state_h.to(device)\n",
        "    state_c = state_c.to(device)\n",
        "    for w in words:\n",
        "        ix = torch.tensor([[vocab_to_int[w]]]).to(device)\n",
        "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
        "    \n",
        "    _, top_ix = torch.topk(output[0], k=100)\n",
        "    choices = top_ix.tolist()\n",
        "    choice = np.random.choice(choices[0])\n",
        "\n",
        "    words.append(int_to_vocab[choice])\n",
        "    for _ in range(40):\n",
        "        ix = torch.tensor([[choice]]).to(device)\n",
        "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
        "\n",
        "        _, top_ix = torch.topk(output[0], k=top_k)\n",
        "        choices = top_ix.tolist()\n",
        "        choice = np.random.choice(choices[0])\n",
        "        next_word = int_to_vocab[choice]\n",
        "        words.append(next_word)\n",
        "        \"\"\"if next_word == \"titleend\":\n",
        "            break\"\"\"\n",
        "\n",
        "    print(' '.join(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBaQsgJy1gL4",
        "colab_type": "code",
        "outputId": "8181960c-0beb-48f2-9102-c26ba9284dd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "for _ in range(10):\n",
        "  predict(device, net, [\"<sos>\"], n_vocab, vocab_to_int, int_to_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<sos> Can it be a man in his car in a Cadillac in bed with ? ? ... . textdelimeter He 's an asshole ... you do not a joke , I 've got a new tattoo in this morning <pad> !\n",
            "<sos> unbearable is going out ... ... ... and he dumped him off my car . ... I 'm going in an Apple Maps relationship . I told her I wanted to get to a job in my life textdelimeter They were\n",
            "<sos> They were in bed textdelimeter The girl asks the barman 's office . The other day I do nt know how to give it to a new tattoo . textdelimeter The other is just beating me nuts ! \" What is\n",
            "<sos> Piano , you do n't want a long time ago ? textdelimeter Bison of her ! <pad> I just beat it . I said I 'm starting to the second man ... and I was just a girl that I 've\n",
            "<sos> She asks her sister , \" What do they say ? textdelimeter I get to her ... <pad> - the lightbulb ? <pad> I think I 'd be the wrong way through her mouth ? \" \" I 'll have you\n",
            "<sos> There are the horns are going on a bar .. \" I 'll have my dad 's a woman , I was n't like you \" The librarian asked him \" Hey you , I do nt get my coffee \"\n",
            "<sos> An old lady 's wife . ... and they were going to be my wife ... ? ... ... textdelimeter It would do with my grandfather named . * \" Hey ! ! Get it out ! \" The other replies\n",
            "<sos> The postman textdelimeter \" Way , and a thug have . \" \" Hey no joke , I 've come across . \" And then they were both ways . \" The sadist responds and says : \" Well , \"\n",
            "<sos> This year I could be an arrow in the desert . The librarian asked him why I could n't understand irony . I 'm starting the first one day . I 'm not sure what do I like to hear this\n",
            "<sos> My penis comes out with an elephant in his own pew .. ( mildly offensive / AntiJokes / sexaddicts textdelimeter I 'm starting a stroke that he was just seasonal mind ! ! ( edited and I 'm going on .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCE72Gr61yna",
        "colab_type": "code",
        "outputId": "6b6d8a88-99cb-4310-ffdd-84a78e0babee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "for _ in range(10):\n",
        "  predict(device, net, ['titleone', 'titlestart'], n_vocab, vocab_to_int, int_to_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "titleone titlestart what my friend was going from prison in texas titleend\n",
            "titleone titlestart did it doggie mcdonald everywhere in ? \" titleend\n",
            "titleone titlestart my mom is a dog in his sleep i had my ex girlfriend s birthday party titleend\n",
            "titleone titlestart do a woman was a sweater with to a guy at night . ? ” titleend\n",
            "titleone titlestart what my dog does the titanic go for christmas eve , \" a pedophile and ? \" . . . . ! i asked my wife titleend\n",
            "titleone titlestart my mom asked a woman that he said i was on a lion ! \" i asked me why i thought it s a text . . titleend\n",
            "titleone titlestart i asked her i got in prison titleend\n",
            "titleone titlestart do calories when i was trying that he said she s a girl at a tree with my friend and a new restaurant , titleend\n",
            "titleone titlestart my mom is a great new car accident at my door , but i told it titleend\n",
            "titleone titlestart did do years old man on my girlfriend and i m scrambling and my friends s favourite fruit factory . titleend\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTp5S8Et2DKZ",
        "colab_type": "code",
        "outputId": "0be51708-3a30-4545-f40a-e3a96f7f7f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "for _ in range(10):\n",
        "  predict(device, net, ['titlefive', 'titlestart'], n_vocab, vocab_to_int, int_to_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "titlefive titlestart schrodinger titleend\n",
            "titlefive titlestart mayonnaise just got in a tank . \" \" i m gonna start to the zoo ? ( x - \" \" \" titleend\n",
            "titlefive titlestart schrodinger . titleend\n",
            "titlefive titlestart a woman has an erection ? . the way of the first day . \" titleend\n",
            "titlefive titlestart a woman has the first iteration - shirt . titleend\n",
            "titlefive titlestart mayonnaise titleend\n",
            "titlefive titlestart jose can tell you re going on an elevator yesterday for her hair about it titleend\n",
            "titlefive titlestart a guy has died titleend\n",
            "titlefive titlestart jose has the worst a riot , titleend\n",
            "titlefive titlestart wwe to a prostitute with a lightbulb titleend\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "114230aA2YJW",
        "colab_type": "code",
        "outputId": "6049d01c-a329-4b3b-c088-707c9c802781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "in_text[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   23,     0,     9, ...,    95,   205,    50],\n",
              "       [    7,     9,   151, ...,    42,    82,     1],\n",
              "       [   24,     0,    19, ...,     2,  1505,     4],\n",
              "       ...,\n",
              "       [   38,   575, 17894, ...,   340,  3098,    12],\n",
              "       [ 7137,    27,     4, ...,   246,    30,     5],\n",
              "       [ 5095,   105,  1217, ...,     1,     3,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dQqkfaP24kK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! grep -i \"Man A: Would you suck my cock if I cleaned it?\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}